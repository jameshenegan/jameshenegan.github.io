<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>

<style>
body {
  font-family: "Avenir Next", Helvetica, Arial, sans-serif;
  padding: 1em;
  margin: auto;
  max-width: 42em;
  background: #fefefe;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  font-weight: bold;
}

h1 {
  color: #000000;
  font-size: 28pt;
}

h2 {
  border-bottom: 1px solid #cccccc;
  color: #000000;
  font-size: 24px;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777777;
  background-color: inherit;
  font-size: 14px;
}

hr {
  height: 0.2em;
  border: 0;
  color: #cccccc;
  background-color: #cccccc;
}

p,
blockquote,
ul,
ol,
dl,
li,
table,
pre {
  margin: 15px 0;
}

img {
  max-width: 100%;
}

table {
  border-collapse: collapse;
  width: 100%;
}

table,
th,
td {
  border: 1px solid #eaeaea;

  border-radius: 3px;
  padding: 5px;
}

tr:nth-child(even) {
  background-color: #f8f8f8;
}

a,
a:visited {
  color: #4183c4;
  background-color: inherit;
  text-decoration: none;
}

#message {
  border-radius: 6px;
  border: 1px solid #ccc;
  display: block;
  width: 100%;
  height: 60px;
  margin: 6px 0px;
}

button,
#ws {
  font-size: 10pt;
  padding: 4px 6px;
  border-radius: 5px;
  border: 1px solid #bbb;
  background-color: #eee;
}

code,
pre,
#ws,
#message {
  font-family: Monaco, monospace;
  font-size: 10pt;
  border-radius: 3px;
  background-color: #f8f8f8;
  color: inherit;
}

code {
  border: 1px solid #eaeaea;
  margin: 0 2px;
  padding: 0 5px;
}

pre {
  border: 1px solid #cccccc;
  overflow: auto;
  padding: 4px 8px;
}

pre > code {
  border: 0;
  margin: 0;
  padding: 0;
}

#ws {
  background-color: #f8f8f8;
}

.send {
  color: #77bb77;
}
.server {
  color: #7799bb;
}
.error {
  color: #aa0000;
}
</style>


     </head>
  <body><h1 id="chapter-2.-data-representation-design-patterns">Chapter 2. Data
Representation Design Patterns</h1>
<p>Machine learning models rely on mathematical functions that require
specific types of data to operate effectively. However, real-world data
often needs to be transformed to fit these requirements. For example,
decision trees work with boolean variables, but data like a baby’s
weight or the hospital they were born in must be converted into boolean
values before the model can use them. This transformation process is
known as feature engineering, where input data is transformed into
features that the model can handle.</p>
<p>In some cases, models can learn these data representations on their
own, such as through embeddings in deep learning, which allow the model
to create more concise and meaningful representations of complex data.
Decision trees can also learn representations, such as thresholding
numerical values to create boolean features.</p>
<p>There are different ways to design these representations. For
instance, oblique decision trees can process linear combinations of
multiple inputs, which can improve accuracy and efficiency compared to
simpler stepwise models. In addition, various design patterns, like the
Hashed Feature and Multimodal Input patterns, offer ways to handle
different types of data or simplify the representation process.</p>
<p>Ultimately, data transformation is crucial for ensuring that machine
learning models can effectively work with real-world inputs, enhancing
their performance and accuracy.</p>
<h3 id="simple-data-representations">Simple Data Representations</h3>
<h4 id="numerical-inputs">Numerical Inputs:</h4>
<p>For numeric data, scaling is crucial, especially for optimizers like
gradient descent, which perform better with values in the range [-1, 1].
This helps models converge faster and reduces computational load.
Different scaling techniques include:</p>
<ul>
<li><strong>Min-max scaling</strong>: Adjusts values between a specific
range, but may be skewed by outliers.</li>
<li><strong>Clipping</strong>: Limits extreme values by capping them at
predefined thresholds.</li>
<li><strong>Z-score normalization</strong>: Scales data using the mean
and standard deviation, addressing outliers while keeping most values
within the [-1, 1] range.</li>
<li><strong>Winsorizing</strong>: Clips outliers using percentiles to
make the data more robust.</li>
</ul>
<p>Nonlinear transformations like logarithms or Box-Cox can also be
applied when data is skewed, helping to improve distributions before
scaling.</p>
<h4 id="categorical-inputs">Categorical Inputs:</h4>
<p>Since most models work with numerical values, categorical data needs
to be converted into numerical representations. Common techniques
include:</p>
<ul>
<li><strong>One-hot encoding</strong>: Converts categories into binary
vectors, ensuring the categories remain independent of one another.</li>
<li><strong>Dummy coding</strong>: A more compact version of one-hot
encoding, often used in statistical models.</li>
<li><strong>Bucketing</strong>: Groups numeric variables into categories
(e.g., day of the week or age ranges) to simplify modeling when
relationships between values are non-continuous.</li>
</ul>
<p>For arrays of categorical or numerical data, common strategies
include summarizing them with statistics (like mean or count),
representing relative frequencies, or selecting a fixed number of items
from ordered arrays.</p>
<p>Overall, proper data representation—whether through scaling,
encoding, or summarizing—is essential for ensuring machine learning
models perform effectively and generalize well to new data.</p>
<h3 id="design-pattern-1-hashed-feature">Design Pattern 1: Hashed
Feature</h3>
<p>The <strong>Hashed Feature</strong> design pattern addresses
challenges with categorical variables in machine learning, including
incomplete vocabulary, high cardinality, and cold start issues. It works
by hashing categorical inputs into a fixed number of buckets, trading
off some accuracy for efficiency.</p>
<h4 id="problems-addressed">Problems Addressed:</h4>
<ol type="1">
<li><strong>Incomplete vocabulary</strong>: Some categorical values may
not appear in training data, leading to issues when the model encounters
unseen values in production.</li>
<li><strong>High cardinality</strong>: When categorical variables have
many possible values (e.g., thousands of hospital IDs), one-hot encoding
creates very large feature vectors that require significant memory and
computational resources.</li>
<li><strong>Cold start</strong>: New categories, like newly built
hospitals, can appear after the model is deployed, creating challenges
for prediction.</li>
</ol>
<h4 id="solution">Solution:</h4>
<p>The hashed feature pattern resolves these issues by:</p>
<ul>
<li><strong>Hashing categorical inputs</strong> into numerical
representations using a deterministic algorithm (e.g., FarmHash),
ensuring the same value is always hashed consistently.</li>
<li><strong>Using a modulo operation</strong> to map the hashed value to
a smaller number of buckets (e.g., 10, 100). This allows the model to
handle new and unseen values, as they will still fall into an existing
bucket.</li>
</ul>
<p>For example, an airport code is hashed into a set number of buckets,
grouping similar airports. This prevents issues with missing or new
airport codes and reduces memory requirements by handling only the
bucket numbers instead of each unique airport code.</p>
<h4 id="trade-offs">Trade-offs:</h4>
<ol type="1">
<li><strong>Loss of accuracy</strong>: Hashing can lead to collisions,
where multiple categorical values share the same bucket, compromising
accuracy.</li>
<li><strong>Bucket collisions</strong>: Choosing too few buckets
increases the likelihood that distinct categories will be grouped
together, reducing model precision.</li>
<li><strong>Skewed distribution</strong>: Categories with high frequency
(e.g., large airports) may dominate the predictions for other categories
in the same bucket.</li>
</ol>
<p>To balance these trade-offs, it’s important to choose the number of
buckets wisely and treat this as a hyperparameter to be tuned. In some
cases, adding aggregate features, like the probability of on-time
flights, can help mitigate accuracy loss due to hashing.</p>
<h4 id="alternatives">Alternatives:</h4>
<ul>
<li><strong>One-hot encoding</strong>: Effective when the categorical
variable has a small vocabulary but impractical for high-cardinality
inputs.</li>
<li><strong>Aggregate features</strong>: Useful when bucket collisions
occur, adding additional predictive power without directly relying on
the hashed feature.</li>
</ul>
<p>By using hashed features, models can handle high-cardinality and
cold-start issues efficiently, but at the cost of some precision. The
choice of hash buckets is critical to achieving the right balance
between performance and accuracy.</p>
<h3 id="design-pattern-2-embeddings">Design Pattern 2: Embeddings</h3>
<p>The <strong>Embeddings</strong> design pattern is a method for
transforming high-cardinality data (such as categorical, text, or image
inputs) into a dense, lower-dimensional representation, preserving
essential information relevant to the learning task. This method
overcomes the limitations of sparse, high-dimensional representations
like one-hot encoding, making it a cornerstone in modern machine
learning.</p>
<h4 id="problem">Problem:</h4>
<p>Handling high-cardinality data using traditional one-hot encoding is
inefficient, especially for data types like customer IDs, product IDs,
text, and images. One-hot encoding leads to sparse matrices and treats
all categories as independent, ignoring relationships (e.g., “twins” and
“triplets” in a birth dataset are treated the same as “twins” and
“quintuplets”). High-cardinality categories also create challenges in
managing memory and computation.</p>
<h4 id="solution-1">Solution:</h4>
<p>Embeddings address these issues by mapping high-dimensional
categorical inputs into lower-dimensional, dense vectors. This is done
using an <strong>embedding layer</strong> in a neural network, which
learns optimal representations of data during training through gradient
descent. These representations capture closeness relationships between
similar categories, improving the model’s ability to identify patterns
and relationships in the data.</p>
<p>For example, an embedding layer can represent customer interactions
with videos, turning sparse one-hot encoded inputs (e.g., customer IDs
or video IDs) into meaningful dense vectors. Similarly, words in a text
can be transformed into word embeddings that capture semantic
relationships (e.g., “walk” is closer to “run” than “book”).</p>
<h4 id="why-it-works">Why It Works:</h4>
<p>Embedding layers learn weights through the training process,
capturing important relationships between categories. For example, in
text embeddings, words that are contextually similar (e.g., “king” and
“queen”) are placed close together in the embedding space. In image
tasks, convolutional neural networks can be used to generate embeddings
for visual content by extracting relevant features.</p>
<h4 id="applications">Applications:</h4>
<ul>
<li><strong>Text embeddings</strong>: Pre-trained models like Word2Vec
and BERT provide dense vector representations of words, capturing
semantic meanings.</li>
<li><strong>Image embeddings</strong>: Convolutional neural networks
(like ResNet or Inception) can generate low-dimensional representations
of images, often used in tasks like image captioning or
classification.</li>
<li><strong>Structured data</strong>: Embeddings can be used for
categorical data such as product IDs or customer IDs, simplifying the
feature engineering process and improving model generalization.</li>
</ul>
<h4 id="trade-offs-1">Trade-offs:</h4>
<p>The main trade-off with embeddings is the potential loss of
information when reducing the dimensionality of data. However,
embeddings offer significant advantages in terms of computational
efficiency and the ability to capture relationships between categories.
The optimal embedding dimension is often determined through
experimentation, balancing accuracy and computational efficiency.</p>
<h4 id="alternatives-1">Alternatives:</h4>
<p>For high-dimensional data, techniques like
<strong>autoencoders</strong> can be used to learn embeddings in an
unsupervised manner, reducing the need for labeled data.
<strong>Pre-trained embeddings</strong> from models like BERT or
Word2Vec can also be used for downstream tasks, enhancing performance
and reducing the need for large labeled datasets.</p>
<p>In summary, embeddings are a powerful way to handle high-cardinality
data in machine learning by creating dense, lower-dimensional
representations that preserve relationships and improve model
efficiency. They are widely used in tasks involving text, images, and
structured data, and are central to modern machine learning
workflows.</p>
<h3 id="design-pattern-3-feature-cross">Design Pattern 3: Feature
Cross</h3>
<p>The <strong>Feature Cross</strong> design pattern enhances machine
learning models by explicitly creating new features that represent
combinations of existing input features. This allows models to learn
relationships between inputs faster and more efficiently, particularly
in situations where the data is not linearly separable.</p>
<h4 id="problem-1">Problem:</h4>
<p>In cases where a model cannot find a linear boundary between classes
using only individual input features, making the model more complex
(e.g., by adding layers) is one solution. However, a simpler and faster
approach is to create <strong>feature crosses</strong>, which encode
nonlinearity by combining features, helping the model learn interactions
between them.</p>
<h4 id="solution-2">Solution:</h4>
<p>A <strong>feature cross</strong> is a synthetic feature formed by
combining two or more categorical (or bucketized numerical) features,
capturing their interaction. This technique allows simpler models, like
linear models, to learn complex relationships without needing more
complex architectures like deep neural networks. For instance, creating
a feature cross of two variables (such as day of the week and hour of
the day) can help a model recognize that Monday at 5 p.m. is different
from Friday at 5 p.m. in predicting outcomes like taxi fare.</p>
<p>By combining features explicitly, feature crosses can:</p>
<ul>
<li>Encode nonlinearities in the data.</li>
<li>Speed up model training.</li>
<li>Reduce the need for large, complex models by enabling simpler models
to perform well.</li>
</ul>
<h4 id="example">Example:</h4>
<p>In a dataset of taxi rides, features like the day of the week and
hour of the day can be crossed to form a 168-dimensional one-hot encoded
vector (7 days × 24 hours). This enables the model to treat “Monday at 5
p.m.” differently from “Friday at 5 p.m.” and capture patterns in taxi
fares more effectively.</p>
<p>In BigQuery ML, feature crosses can be created using the
<code>ML.FEATURE_CROSS</code> function. In TensorFlow, feature crosses
can be created using <code>tf.feature_column.crossed_column</code>.</p>
<h4 id="why-it-works-1">Why It Works:</h4>
<p>Feature crosses help by increasing the expressiveness of simple
models, allowing them to learn more complex relationships between
features without additional layers or complex structures. For example,
crossing the features of “is_male” and “plurality” in a birth dataset
allows the model to treat different gender-plurality combinations (e.g.,
male twins vs. female triplets) separately, enhancing predictive
power.</p>
<h4 id="trade-offs-and-alternatives">Trade-offs and Alternatives:</h4>
<ol type="1">
<li><strong>Handling numerical features</strong>: Feature crosses are
typically used with categorical data, but numerical data can be
bucketized before crossing. For instance, latitude and longitude can be
bucketized to represent geographical locations, then crossed.</li>
<li><strong>Sparsity</strong>: Feature crosses can lead to
high-dimensional and sparse feature spaces. To mitigate this, embedding
layers (as described in the Embeddings design pattern) can be used to
reduce dimensionality and generalize the relationships between crossed
features.</li>
<li><strong>High cardinality</strong>: Combining features with large
cardinalities can lead to a huge number of combinations, making models
prone to overfitting. Regularization techniques like L1 or L2 can help
prevent overfitting by reducing the influence of less important
features.</li>
</ol>
<p>In summary, the Feature Cross pattern is a powerful method for
enhancing model expressiveness by explicitly capturing interactions
between features, leading to simpler, faster models that can perform
well without complex architectures. However, care must be taken with
high-cardinality features and sparse feature spaces, often requiring
regularization or embedding techniques to handle these challenges
effectively.</p>
<h3 id="design-pattern-4-multimodal-input-design">Design Pattern 4:
Multimodal Input Design</h3>
<p>The <strong>Multimodal Input</strong> design pattern allows machine
learning models to handle and combine multiple types of data inputs,
such as images, text, and structured (tabular) data. This pattern is
useful when building models that need to consider various data formats,
enhancing the model’s ability to identify patterns across different
input types.</p>
<h4 id="problem-2">Problem:</h4>
<p>Many machine learning models are built to handle specific types of
data, such as images or text, but cannot process different formats
together. For example, a model that classifies traffic violations might
need to analyze both image data (footage of the violation) and
structured data (metadata like time of day or weather conditions).
Similarly, models that combine text (like reviews) with structured data
(such as prices or meal type) require a way to process these inputs
together.</p>
<h4 id="solution-3">Solution:</h4>
<p>The <strong>Multimodal Input</strong> pattern solves this by
combining different input representations into a single model. For
example, text data can be represented as embeddings or bag of words
(BOW), while structured data (e.g., numerical or categorical data) can
be one-hot encoded or normalized. The representations are concatenated
to form a single input array for the model. Using Keras’s functional
API, different types of input layers (e.g., embedding layers for text
and dense layers for tabular data) are merged, allowing the model to
process all the data together.</p>
<h4 id="example-1">Example:</h4>
<ul>
<li><strong>Text + Tabular Data</strong>: In a restaurant review
prediction model, review text is represented through embeddings, while
tabular data (meal price, meal type) is encoded as one-hot vectors or
numbers. These are concatenated into a single input array for the model
to predict the rating.</li>
<li><strong>Image + Metadata</strong>: In a model analyzing traffic
footage, the image is processed using convolutional layers, while
additional data like time, weather, and location are passed through
dense layers. These inputs are then combined to predict whether a
traffic violation occurred.</li>
</ul>
<h4 id="trade-offs-and-alternatives-1">Trade-offs and Alternatives:</h4>
<ul>
<li><strong>Combining multiple representations</strong>: Multimodal
inputs can also represent the same data in different ways. For example,
text data can be represented both as BOW and embeddings to capture
different aspects of the data. This provides richer input and helps the
model recognize more patterns.</li>
<li><strong>Handling numerical data</strong>: Numeric inputs can be
represented as both continuous and bucketized categorical data, allowing
models to understand both the exact values and broader categories.</li>
</ul>
<h4 id="why-it-works-2">Why It Works:</h4>
<p>By combining different data types or representations, the Multimodal
Input pattern allows the model to learn from various sources of
information, making it more robust and improving its predictive power.
This pattern is particularly useful for complex real-world tasks where
data comes in diverse forms, such as combining visual and contextual
information for decision-making.</p>
<p>In summary, the Multimodal Input design pattern enhances machine
learning models by enabling them to process and learn from a variety of
input types, combining structured data, text, images, and other formats
into a single, cohesive model.</p>
    
</body>
</html>