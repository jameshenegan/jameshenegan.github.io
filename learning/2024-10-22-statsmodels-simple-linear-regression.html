<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>

<style>
body {
  font-family: "Avenir Next", Helvetica, Arial, sans-serif;
  padding: 1em;
  margin: auto;
  max-width: 42em;
  background: #fefefe;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  font-weight: bold;
}

h1 {
  color: #000000;
  font-size: 28pt;
}

h2 {
  border-bottom: 1px solid #cccccc;
  color: #000000;
  font-size: 24px;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777777;
  background-color: inherit;
  font-size: 14px;
}

hr {
  height: 0.2em;
  border: 0;
  color: #cccccc;
  background-color: #cccccc;
}

p,
blockquote,
ul,
ol,
dl,
li,
table,
pre {
  margin: 15px 0;
}

img {
  max-width: 100%;
}

table {
  border-collapse: collapse;
  width: 100%;
}

table,
th,
td {
  border: 1px solid #eaeaea;

  border-radius: 3px;
  padding: 5px;
}

tr:nth-child(even) {
  background-color: #f8f8f8;
}

a,
a:visited {
  color: #4183c4;
  background-color: inherit;
  text-decoration: none;
}

#message {
  border-radius: 6px;
  border: 1px solid #ccc;
  display: block;
  width: 100%;
  height: 60px;
  margin: 6px 0px;
}

button,
#ws {
  font-size: 10pt;
  padding: 4px 6px;
  border-radius: 5px;
  border: 1px solid #bbb;
  background-color: #eee;
}

code,
pre,
#ws,
#message {
  font-family: Monaco, monospace;
  font-size: 10pt;
  border-radius: 3px;
  background-color: #f8f8f8;
  color: inherit;
}

code {
  border: 1px solid #eaeaea;
  margin: 0 2px;
  padding: 0 5px;
}

pre {
  border: 1px solid #cccccc;
  overflow: auto;
  padding: 4px 8px;
}

pre > code {
  border: 0;
  margin: 0;
  padding: 0;
}

#ws {
  background-color: #f8f8f8;
}

.send {
  color: #77bb77;
}
.server {
  color: #7799bb;
}
.error {
  color: #aa0000;
}
</style>


     </head>
  <body><h2 id="simple-linear-regression-with-statsmodels">Simple Linear
Regression with <code>statsmodels</code></h2>
<h3 id="introduction-to-simple-linear-regression"><strong>1.
Introduction to Simple Linear Regression</strong></h3>
<p>Simple Linear Regression is a statistical method used to model the
relationship between a dependent variable (response) and an independent
variable (predictor). The linear regression model assumes a linear
relationship between the variables:</p>
<p>[ y = _0 + _1 x + ]</p>
<p>Where:</p>
<ul>
<li>( y ) is the dependent variable.</li>
<li>( x ) is the independent variable.</li>
<li>( _0 ) is the intercept.</li>
<li>( _1 ) is the slope (coefficient).</li>
<li>( ) is the error term.</li>
</ul>
<p>We’ll use the <code>statsmodels</code> library to estimate these
coefficients and build a simple linear regression model.</p>
<hr />
<h3 id="installation-of-required-libraries"><strong>2. Installation of
Required Libraries</strong></h3>
<p>First, make sure you have the necessary libraries installed. You can
install <code>statsmodels</code>, <code>numpy</code>, and
<code>matplotlib</code> using <code>pip</code>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install statsmodels numpy matplotlib</span></code></pre></div>
<hr />
<h3 id="import-libraries"><strong>3. Import Libraries</strong></h3>
<p>Let’s start by importing the required libraries:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
<hr />
<h3 id="create-or-load-data"><strong>4. Create or Load
Data</strong></h3>
<p>For this example, let’s create a simple dataset with one independent
variable <code>x</code> and one dependent variable <code>y</code>.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a sample dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.rand(<span class="dv">100</span>) <span class="op">*</span> <span class="dv">10</span>  <span class="co"># Independent variable (random data between 0 and 10)</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="fl">2.5</span> <span class="op">*</span> x <span class="op">+</span> np.random.randn(<span class="dv">100</span>) <span class="op">*</span> <span class="dv">2</span>  <span class="co"># Dependent variable with noise</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame to hold the data</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">&#39;x&#39;</span>: x, <span class="st">&#39;y&#39;</span>: y})</span></code></pre></div>
<p>This creates a dataset where <code>y</code> is linearly dependent on
<code>x</code> with some added noise.</p>
<hr />
<h3 id="visualize-the-data"><strong>5. Visualize the Data</strong></h3>
<p>It’s always a good idea to visualize the data before running the
regression to understand the relationship.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[<span class="st">&#39;x&#39;</span>], data[<span class="st">&#39;y&#39;</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Independent Variable (x)&#39;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Dependent Variable (y)&#39;</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Scatter Plot of x vs y&#39;</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p>You should see a scatter plot where the data points form a roughly
linear pattern, indicating that linear regression is appropriate.</p>
<hr />
<h3 id="add-a-constant-term-intercept"><strong>6. Add a Constant Term
(Intercept)</strong></h3>
<p><code>statsmodels</code> does not automatically include the intercept
(constant term) in the regression model, so we need to add it
manually.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a constant (intercept term)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(data[<span class="st">&#39;x&#39;</span>])  <span class="co"># This adds a column of 1s to the independent variable for the intercept</span></span></code></pre></div>
<p>Here, <code>X</code> now contains two columns: one for the intercept
and one for the independent variable <code>x</code>.</p>
<hr />
<h3 id="fit-the-simple-linear-regression-model"><strong>7. Fit the
Simple Linear Regression Model</strong></h3>
<p>Now that we have the data ready, we can fit the linear regression
model.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the regression model</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(data[<span class="st">&#39;y&#39;</span>], X).fit()</span></code></pre></div>
<ul>
<li><code>sm.OLS</code> stands for Ordinary Least Squares, the method
used for fitting the linear regression model.</li>
<li>The <code>.fit()</code> method performs the actual fitting
process.</li>
</ul>
<hr />
<h3 id="view-the-regression-results"><strong>8. View the Regression
Results</strong></h3>
<p>Once the model is fit, we can summarize the results.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View the regression results</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code></pre></div>
<p>The <code>.summary()</code> method provides a detailed output,
including:</p>
<ul>
<li>Coefficients (Intercept and Slope),</li>
<li>R-squared value (which tells how well the model fits the data),</li>
<li>p-values (for statistical significance),</li>
<li>Standard errors, and more.</li>
</ul>
<h3 id="example-output"><strong>Example Output:</strong></h3>
<pre><code>                            OLS Regression Results
==============================================================================
Dep. Variable:                      y   R-squared:                       0.878
Model:                            OLS   Adj. R-squared:                  0.876
Method:                 Least Squares   F-statistic:                     715.4
Date:                Thu, 22 Oct 2024   Prob (F-statistic):           4.25e-45
Time:                        14:00:17   Log-Likelihood:                -209.58
No. Observations:                 100   AIC:                             423.2
Df Residuals:                      98   BIC:                             428.4
Df Model:                           1
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.5294      0.637      0.830      0.409      -0.735       1.794
x              2.4635      0.092     26.743      0.000       2.280       2.647
==============================================================================
Omnibus:                        0.149   Durbin-Watson:                   1.947
Prob(Omnibus):                  0.928   Jarque-Bera (JB):                0.334
Skew:                           0.051   Prob(JB):                        0.846
Kurtosis:                       2.710   Cond. No.                         11.9
==============================================================================</code></pre>
<ul>
<li>The <strong>R-squared</strong> value of 0.878 means that 87.8% of
the variability in <code>y</code> can be explained by
<code>x</code>.</li>
<li>The <strong>p-value</strong> for the slope (under the column
<code>P&gt;|t|</code>) is very small (0.000), which indicates that
<code>x</code> is statistically significant.</li>
</ul>
<hr />
<h3 id="interpreting-the-coefficients"><strong>9. Interpreting the
Coefficients</strong></h3>
<p>From the summary, we can extract the coefficients:</p>
<ul>
<li><strong>Intercept (const)</strong> = 0.5294</li>
<li><strong>Slope (x)</strong> = 2.4635</li>
</ul>
<p>Thus, the equation of the regression line is:</p>
<p>[ y = 0.5294 + 2.4635 x ]</p>
<p>This means that for every 1 unit increase in <code>x</code>, the
value of <code>y</code> increases by approximately 2.46 units.</p>
<hr />
<h3 id="make-predictions"><strong>10. Make Predictions</strong></h3>
<p>We can use the model to make predictions. For example, if you want to
predict <code>y</code> for a given value of <code>x = 5</code>:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># New data point for prediction</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>new_data <span class="op">=</span> pd.DataFrame({<span class="st">&#39;x&#39;</span>: [<span class="dv">5</span>]})</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>new_data <span class="op">=</span> sm.add_constant(new_data)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Make prediction</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> model.predict(new_data)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Predicted value of y for x=5:&quot;</span>, prediction[<span class="dv">0</span>])</span></code></pre></div>
<hr />
<h3 id="visualize-the-regression-line"><strong>11. Visualize the
Regression Line</strong></h3>
<p>Finally, let’s visualize the regression line along with the data
points.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of the original data</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[<span class="st">&#39;x&#39;</span>], data[<span class="st">&#39;y&#39;</span>], label<span class="op">=</span><span class="st">&quot;Data&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the regression line</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">&#39;x&#39;</span>], model.predict(X), color<span class="op">=</span><span class="st">&#39;red&#39;</span>, label<span class="op">=</span><span class="st">&quot;Regression Line&quot;</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Independent Variable (x)&#39;</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Dependent Variable (y)&#39;</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Linear Regression&#39;</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<hr />
<h3 id="residual-analysis"><strong>12. Residual Analysis</strong></h3>
<p>Residuals (the difference between observed and predicted values)
should be randomly distributed. We can plot the residuals to check this
assumption.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residuals</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> data[<span class="st">&#39;y&#39;</span>] <span class="op">-</span> model.predict(X)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot residuals</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[<span class="st">&#39;x&#39;</span>], residuals)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Independent Variable (x)&#39;</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Residuals&#39;</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Residual Plot&#39;</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p>A well-fitted model should have residuals scattered randomly around
0.</p>
<hr />
<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>In this tutorial, you learned how to:</p>
<ol type="1">
<li>Set up and visualize data for linear regression.</li>
<li>Perform simple linear regression using
<code>statsmodels</code>.</li>
<li>Interpret the regression results and make predictions.</li>
<li>Visualize the fitted regression line and analyze residuals.</li>
</ol>
<p>You can expand this analysis by including more features (independent
variables) to perform <strong>multiple linear regression</strong>.</p>
<h2 id="uncertainty">Uncertainty</h2>
<p>It is possible to illustrate the uncertainty in the slope of the
linear regression model. The uncertainty is typically represented using
confidence intervals or prediction intervals around the estimated
regression line. These intervals give us an idea of how much the true
slope and predicted values could vary due to randomness in the data.</p>
<p>Here are a few common ways to illustrate this uncertainty:</p>
<h3 id="confidence-intervals-for-the-slope"><strong>1. Confidence
Intervals for the Slope</strong></h3>
<p>Confidence intervals around the slope provide a range of plausible
values for the slope, given the data. The <code>statsmodels</code>
output includes the confidence intervals for each of the coefficients.
You can extract and plot the confidence interval for the slope.</p>
<h3 id="confidence-bands-for-the-regression-line"><strong>2. Confidence
Bands for the Regression Line</strong></h3>
<p>Confidence bands give you an interval around the predicted values of
the regression line. These intervals represent the uncertainty about the
estimated regression line itself (i.e., where the true regression line
might be).</p>
<h3 id="prediction-intervals"><strong>3. Prediction
Intervals</strong></h3>
<p>Prediction intervals give you an interval around the predicted
response values (dependent variable) for new data points. These
intervals are wider than confidence intervals because they also account
for the error in future observations, not just the uncertainty in the
estimated model.</p>
<p>Let’s focus on plotting <strong>confidence bands</strong> for the
regression line and how you can visualize uncertainty in the slope.</p>
<h3 id="steps-to-plot-confidence-bands-for-the-regression-line">Steps to
Plot Confidence Bands for the Regression Line</h3>
<p>We can calculate and plot the confidence intervals around the
predicted regression line using <code>statsmodels</code>. Here’s how to
do it:</p>
<hr />
<h3 id="create-data-points-for-confidence-bands"><strong>1. Create Data
Points for Confidence Bands</strong></h3>
<p>After fitting the regression model, we can use the
<code>.get_prediction()</code> method in <code>statsmodels</code> to
calculate the predicted values and their confidence intervals.</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted values and confidence intervals</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model.get_prediction(X)  <span class="co"># X is the independent variable with constant</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>prediction_summary <span class="op">=</span> predictions.summary_frame()  <span class="co"># Summary frame with prediction info</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print first few rows of the prediction summary (for reference)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(prediction_summary.head())</span></code></pre></div>
<p>The <code>summary_frame()</code> method returns a DataFrame with
columns for:</p>
<ul>
<li><code>mean</code>: The predicted values (fitted values from the
regression).</li>
<li><code>mean_ci_lower</code> and <code>mean_ci_upper</code>: The lower
and upper bounds of the 95% confidence interval for the mean.</li>
<li><code>obs_ci_lower</code> and <code>obs_ci_upper</code>: The lower
and upper bounds of the 95% prediction interval for the
observations.</li>
</ul>
<hr />
<h3 id="plot-the-regression-line-with-confidence-bands"><strong>2. Plot
the Regression Line with Confidence Bands</strong></h3>
<p>We can now plot the regression line along with the confidence
intervals for the predicted values.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of original data</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[<span class="st">&#39;x&#39;</span>], data[<span class="st">&#39;y&#39;</span>], label<span class="op">=</span><span class="st">&quot;Data&quot;</span>, color<span class="op">=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the regression line (mean prediction)</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.plot(data[<span class="st">&#39;x&#39;</span>], prediction_summary[<span class="st">&#39;mean&#39;</span>], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, label<span class="op">=</span><span class="st">&quot;Regression Line&quot;</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot confidence interval for the regression line (mean prediction)</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.fill_between(data[<span class="st">&#39;x&#39;</span>],</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>                 prediction_summary[<span class="st">&#39;mean_ci_lower&#39;</span>],</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>                 prediction_summary[<span class="st">&#39;mean_ci_upper&#39;</span>],</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">&#39;lightgray&#39;</span>, label<span class="op">=</span><span class="st">&quot;95% Confidence Interval&quot;</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Independent Variable (x)&#39;</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Dependent Variable (y)&#39;</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Linear Regression with Confidence Interval&#39;</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p>In this plot:</p>
<ul>
<li>The <strong>red line</strong> represents the predicted regression
line.</li>
<li>The <strong>shaded area</strong> represents the 95% confidence
interval for the mean prediction.</li>
</ul>
<h3 id="plot-the-prediction-interval-optional"><strong>3. Plot the
Prediction Interval (Optional)</strong></h3>
<p>You can also visualize the prediction interval, which accounts for
the variability in new observations.</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot prediction interval</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plt.fill_between(data[<span class="st">&#39;x&#39;</span>],</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                 prediction_summary[<span class="st">&#39;obs_ci_lower&#39;</span>],</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                 prediction_summary[<span class="st">&#39;obs_ci_upper&#39;</span>],</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">&#39;lightblue&#39;</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, label<span class="op">=</span><span class="st">&quot;95% Prediction Interval&quot;</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Independent Variable (x)&#39;</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Dependent Variable (y)&#39;</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Linear Regression with Prediction Interval&#39;</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p>In this case:</p>
<ul>
<li>The <strong>blue shaded area</strong> represents the 95% prediction
interval, which is wider than the confidence interval since it accounts
for both the uncertainty in the model and future observations.</li>
</ul>
<hr />
<h3 id="summary"><strong>Summary</strong></h3>
<ul>
<li><strong>Confidence Intervals</strong> give an indication of the
uncertainty in the regression line (where the true line might
fall).</li>
<li><strong>Prediction Intervals</strong> provide an estimate of where
future observations are likely to fall.</li>
<li>By plotting these intervals, you can visually represent the
uncertainty in the slope of the regression model and see how confident
you are in the predictions.</li>
</ul>
    
</body>
</html>