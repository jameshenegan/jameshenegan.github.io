<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>

<style>
body {
  font-family: "Avenir Next", Helvetica, Arial, sans-serif;
  padding: 1em;
  margin: auto;
  max-width: 42em;
  background: #fefefe;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  font-weight: bold;
}

h1 {
  color: #000000;
  font-size: 28pt;
}

h2 {
  border-bottom: 1px solid #cccccc;
  color: #000000;
  font-size: 24px;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777777;
  background-color: inherit;
  font-size: 14px;
}

hr {
  height: 0.2em;
  border: 0;
  color: #cccccc;
  background-color: #cccccc;
}

p,
blockquote,
ul,
ol,
dl,
li,
table,
pre {
  margin: 15px 0;
}

img {
  max-width: 100%;
}

table {
  border-collapse: collapse;
  width: 100%;
}

table,
th,
td {
  border: 1px solid #eaeaea;

  border-radius: 3px;
  padding: 5px;
}

tr:nth-child(even) {
  background-color: #f8f8f8;
}

a,
a:visited {
  color: #4183c4;
  background-color: inherit;
  text-decoration: none;
}

#message {
  border-radius: 6px;
  border: 1px solid #ccc;
  display: block;
  width: 100%;
  height: 60px;
  margin: 6px 0px;
}

button,
#ws {
  font-size: 10pt;
  padding: 4px 6px;
  border-radius: 5px;
  border: 1px solid #bbb;
  background-color: #eee;
}

code,
pre,
#ws,
#message {
  font-family: Monaco, monospace;
  font-size: 10pt;
  border-radius: 3px;
  background-color: #f8f8f8;
  color: inherit;
}

code {
  border: 1px solid #eaeaea;
  margin: 0 2px;
  padding: 0 5px;
}

pre {
  border: 1px solid #cccccc;
  overflow: auto;
  padding: 4px 8px;
}

pre > code {
  border: 0;
  margin: 0;
  padding: 0;
}

#ws {
  background-color: #f8f8f8;
}

.send {
  color: #77bb77;
}
.server {
  color: #7799bb;
}
.error {
  color: #aa0000;
}
</style>


     </head>
  <body><h3 id="shapley-values-tutorial">Shapley Values Tutorial</h3>
<p><strong>Shapley values</strong> are a concept from cooperative game
theory used to fairly distribute the total gains (or payoffs) to players
based on their individual contributions to a cooperative game. In
machine learning, they are often used to interpret the contributions of
individual features in a model’s predictions.</p>
<h3 id="introduction-to-shapley-values">1. <strong>Introduction to
Shapley Values</strong></h3>
<p>Imagine you’re working in a team, and the team’s success depends on
the contributions of all members. The Shapley value is a way to fairly
assign a share of the success (or payoff) to each member, based on their
individual contributions and the value they add by working with
different subsets of the team.</p>
<p>In machine learning, you can think of:</p>
<ul>
<li><strong>Players</strong> as <strong>features</strong> of a
model.</li>
<li><strong>Payoff</strong> as the <strong>prediction</strong> from the
model.</li>
</ul>
<p>Shapley values tell us how much each feature contributes to a
specific prediction by considering all possible combinations of
features.</p>
<h3 id="basic-idea">2. <strong>Basic Idea</strong></h3>
<p>For each feature, the Shapley value represents its average
contribution across all possible combinations of features. Formally, for
each feature (i), the Shapley value is given by:</p>
<p>[ i = ( f(S {i}) - f(S) ) ]</p>
<p>Where:</p>
<ul>
<li>(N) is the set of all features.</li>
<li>(S) is any subset of features excluding feature (i).</li>
<li>(f(S)) is the model’s prediction using the subset (S).</li>
<li>(f(S {i})) is the prediction when adding feature (i) to subset
(S).</li>
</ul>
<h3 id="steps-to-compute-shapley-values">3. <strong>Steps to Compute
Shapley Values</strong></h3>
<p>To compute Shapley values, we follow these steps:</p>
<h4
id="step-1-calculate-the-models-prediction-without-the-feature.">Step 1:
Calculate the model’s prediction without the feature.</h4>
<p>For every feature (i), compute the model’s prediction with different
subsets of the remaining features.</p>
<h4 id="step-2-calculate-the-models-prediction-with-the-feature.">Step
2: Calculate the model’s prediction with the feature.</h4>
<p>Then, compute the prediction when feature (i) is added to the subsets
from Step 1.</p>
<h4 id="step-3-compute-the-marginal-contribution.">Step 3: Compute the
marginal contribution.</h4>
<p>For each subset (S), calculate the difference between the predictions
with and without feature (i). This is called the marginal contribution
of feature (i) for subset (S).</p>
<h4 id="step-4-average-over-all-subsets.">Step 4: Average over all
subsets.</h4>
<p>The Shapley value is the weighted average of the marginal
contributions across all possible subsets. This ensures that each
feature gets a fair share based on how much it adds to the
prediction.</p>
<h3 id="advantages-of-shapley-values">4. <strong>Advantages of Shapley
Values</strong></h3>
<ul>
<li><strong>Fairness</strong>: It provides a fair distribution of
contributions by considering all combinations of features.</li>
<li><strong>Consistency</strong>: If a model’s behavior changes in a way
that increases the importance of a feature, the Shapley value for that
feature will also increase.</li>
<li><strong>Model-agnostic</strong>: It works for any machine learning
model, from linear regression to complex models like neural networks or
tree-based models.</li>
</ul>
<h3 id="example-of-shapley-value-calculation">5. <strong>Example of
Shapley Value Calculation</strong></h3>
<p>Imagine a model predicts house prices based on three features:
<strong>size</strong>, <strong>location</strong>, and <strong>number of
bedrooms</strong>. We want to know how much each feature contributes to
a specific prediction of, say, $500,000.</p>
<ul>
<li>Compute the prediction using different combinations of
features.</li>
<li>Calculate the marginal contributions for each feature.</li>
<li>Average these contributions across all subsets to get the Shapley
value for each feature.</li>
</ul>
<h3 id="using-shap-for-shapley-values-in-python">6. <strong>Using SHAP
for Shapley Values in Python</strong></h3>
<p>Python’s <code>shap</code> library simplifies Shapley value
calculations. Here’s a basic example:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a dataset and train a model (e.g., XGBoost)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> shap.datasets.boston()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> xgboost.XGBRegressor().fit(X, y)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize SHAP explainer</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>explainer <span class="op">=</span> shap.Explainer(model, X)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate SHAP values</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>shap_values <span class="op">=</span> explainer(X)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot SHAP values for a single prediction</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>shap.waterfall_plot(shap_values[<span class="dv">0</span>])</span></code></pre></div>
<h3 id="conclusion">7. <strong>Conclusion</strong></h3>
<p>Shapley values offer a powerful and mathematically grounded way to
interpret the contributions of features in a machine learning model.
While they can be computationally expensive for large models,
approximation methods (like SHAP) make them practical and widely used
for model interpretation.</p>
    
</body>
</html>